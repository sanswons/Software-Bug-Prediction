:::MLPv0.5.0 transformer 1549925378.610088110 (/hb/home/swoonna/.local/bin/t2t-trainer:28) run_set_random_seed
:::MLPv0.5.0 transformer 1549925382.293626547 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
:::MLPv0.5.0 transformer 1549925382.303869486 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/problem.py:872) input_order
:::MLPv0.5.0 transformer 1549925385.994435072 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 28912, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925386.138693094 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0
:::MLPv0.5.0 transformer 1549925386.604787827 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.6
:::MLPv0.5.0 transformer 1549925386.613193512 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1549925386.614457607 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.6
:::MLPv0.5.0 transformer 1549925386.615677595 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"use_bias": "false", "num_heads": 4, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925386.866180420 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925386.867494583 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925386.868753910 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1549925387.173774481 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925387.175077677 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925387.176327944 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1
:::MLPv0.5.0 transformer 1549925387.253759861 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 128}
:::MLPv0.5.0 transformer 1549925387.405350924 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: "DEFERRED: 5fcb744b-dad5-460b-a1ef-52fcfc6ba205"
:::MLPv0.5.0 transformer 1549925387.406369686 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000
:::MLPv0.5.0 transformer 1549925387.419891596 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:53) opt_name: "Adam"
:::MLPv0.5.0 transformer 1549925387.420914888 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 transformer 1549925387.421921730 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997
:::MLPv0.5.0 transformer 1549925387.422937632 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09
:::MLPv0.5.0 transformer 1549925514.116044760 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
:::MLPv0.5.0 transformer 1549925517.673575163 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 28912, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925517.768210649 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0
:::MLPv0.5.0 transformer 1549925518.223968506 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1549925518.226722956 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1549925518.229284525 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1549925518.231837511 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"use_bias": "false", "num_heads": 4, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925518.451554775 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925518.453981161 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925518.456607580 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1549925518.739875078 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925518.741672754 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925518.743431091 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1549925518.807497501 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 128}
:::MLPv0.5.0 transformer 1549925557.378104925 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256
:::MLPv0.5.0 transformer 1549925560.966213703 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {"vocab_size": 28912, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925561.049040794 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0
:::MLPv0.5.0 transformer 1549925561.333062887 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0
:::MLPv0.5.0 transformer 1549925561.335063457 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2
:::MLPv0.5.0 transformer 1549925561.336824894 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0
:::MLPv0.5.0 transformer 1549925561.338591337 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {"use_bias": "false", "num_heads": 4, "hidden_size": 128}
:::MLPv0.5.0 transformer 1549925561.565913677 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925561.569063663 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925561.572136879 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1549925561.849416971 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {"filter_size": 512, "use_bias": "True", "activation": "relu"}
:::MLPv0.5.0 transformer 1549925561.850705385 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {"hidden_size": 128, "use_bias": "True"}
:::MLPv0.5.0 transformer 1549925561.851910830 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0
:::MLPv0.5.0 transformer 1549925561.915247202 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {"hidden_size": 128}
:::MLPv0.5.0 transformer 1549925599.432774544 (/hb/home/swoonna/.local/bin/t2t-trainer:28) run_final
