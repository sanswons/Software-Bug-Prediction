{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hb/home/swoonna/anaconda3/envs/sbp/bin/python3\n",
      "/hb/home/swoonna/anaconda3/envs/sbp/bin/pip\n",
      "/hb/home/swoonna/anaconda3/envs/sbp/bin/jupyter\n",
      "absl-py==0.6.1\n",
      "alembic==1.0.5\n",
      "astor==0.7.1\n",
      "bsddb3==6.2.6\n",
      "bz2file==0.98\n",
      "cachetools==3.0.0\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "Flask==1.0.2\n",
      "future==0.17.1\n",
      "gast==0.2.1.post0\n",
      "gevent==1.3.7\n",
      "google-api-python-client==1.7.6\n",
      "google-auth==1.6.2\n",
      "google-auth-httplib2==0.0.3\n",
      "googleapis-common-protos==1.5.5\n",
      "greenlet==0.4.15\n",
      "grpcio==1.17.1\n",
      "gunicorn==19.9.0\n",
      "Gutenberg==0.7.0\n",
      "gym==0.10.9\n",
      "httplib2==0.12.0\n",
      "idna==2.8\n",
      "isodate==0.6.0\n",
      "itsdangerous==1.1.0\n",
      "Jinja2==2.10\n",
      "Keras-Applications==1.0.6\n",
      "Keras-Preprocessing==1.0.5\n",
      "Mako==1.0.7\n",
      "Markdown==3.0.1\n",
      "MarkupSafe==1.1.0\n",
      "mesh-tensorflow==0.0.5\n",
      "mpmath==1.1.0\n",
      "nltk==3.4\n",
      "numpy==1.15.4\n",
      "oauth2client==4.1.3\n",
      "pandas==0.23.4\n",
      "promise==2.2.1\n",
      "protobuf==3.6.1\n",
      "pyasn1==0.4.5\n",
      "pyasn1-modules==0.2.2\n",
      "pyglet==1.3.2\n",
      "python-editor==1.0.3\n",
      "pytz==2018.9\n",
      "rdflib==4.2.2\n",
      "rdflib-sqlalchemy==0.3.8\n",
      "requests==2.21.0\n",
      "rsa==4.0\n",
      "scipy==1.2.0\n",
      "singledispatch==3.4.0.3\n",
      "SQLAlchemy==1.2.15\n",
      "sympy==1.3\n",
      "tensor2tensor==1.11.0\n",
      "tensorboard==1.12.2\n",
      "tensorflow==1.12.0\n",
      "tensorflow-gpu==1.12.0\n",
      "tensorflow-metadata==0.9.0\n",
      "tensorflow-probability==0.5.0\n",
      "termcolor==1.1.0\n",
      "tfds-nightly==0.0.2.dev201812180014\n",
      "toolz==0.9.0\n",
      "tqdm==4.29.0\n",
      "typing==3.6.6\n",
      "uritemplate==3.0.0\n",
      "urllib3==1.24.1\n",
      "Werkzeug==0.14.1\n",
      "wrapt==1.10.11\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "which python3\n",
    "which pip\n",
    "which jupyter\n",
    "pip freeze --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.12 in /hb/home/swoonna/.local/lib/python3.6/site-packages (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (0.6.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (0.2.1.post0)\n",
      "Requirement already satisfied: wheel>=0.26 in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from tensorflow==1.12) (0.32.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from tensorflow==1.12) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.0.5)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.12.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.17.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (3.6.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (0.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow==1.12) (1.15.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.12) (40.6.3)\n",
      "Requirement already satisfied: h5py in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.9.0)\n",
      "Requirement already satisfied: tensor2tensor in /hb/home/swoonna/.local/lib/python3.6/site-packages (1.11.0)\n",
      "Requirement already satisfied: scipy in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.2.0)\n",
      "Requirement already satisfied: future in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.17.1)\n",
      "Requirement already satisfied: six in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from tensor2tensor) (1.12.0)\n",
      "Requirement already satisfied: h5py in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from tensor2tensor) (2.9.0)\n",
      "Requirement already satisfied: requests in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (2.21.0)\n",
      "Requirement already satisfied: tfds-nightly in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.0.2.dev201812180014)\n",
      "Requirement already satisfied: tqdm in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (4.29.0)\n",
      "Requirement already satisfied: google-api-python-client in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.7.6)\n",
      "Requirement already satisfied: mesh-tensorflow in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.0.5)\n",
      "Requirement already satisfied: tensorflow-probability in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.5.0)\n",
      "Requirement already satisfied: oauth2client in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (4.1.3)\n",
      "Requirement already satisfied: bz2file in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.98)\n",
      "Requirement already satisfied: flask in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.0.2)\n",
      "Requirement already satisfied: gym in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (0.10.9)\n",
      "Requirement already satisfied: gevent in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.3.7)\n",
      "Requirement already satisfied: gunicorn in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (19.9.0)\n",
      "Requirement already satisfied: numpy in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.15.4)\n",
      "Requirement already satisfied: sympy in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensor2tensor) (1.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from requests->tensor2tensor) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from requests->tensor2tensor) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from requests->tensor2tensor) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from requests->tensor2tensor) (2.8)\n",
      "Requirement already satisfied: tensorflow-metadata in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (1.10.11)\n",
      "Requirement already satisfied: promise in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (2.2.1)\n",
      "Requirement already satisfied: termcolor in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (1.1.0)\n",
      "Requirement already satisfied: protobuf in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (3.6.1)\n",
      "Requirement already satisfied: pytz in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tfds-nightly->tensor2tensor) (2018.9)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from google-api-python-client->tensor2tensor) (0.12.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from google-api-python-client->tensor2tensor) (0.0.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from google-api-python-client->tensor2tensor) (3.0.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from google-api-python-client->tensor2tensor) (1.6.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from oauth2client->tensor2tensor) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from oauth2client->tensor2tensor) (0.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from oauth2client->tensor2tensor) (0.4.5)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from flask->tensor2tensor) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from flask->tensor2tensor) (2.10)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from flask->tensor2tensor) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from flask->tensor2tensor) (7.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from gym->tensor2tensor) (1.3.2)\n",
      "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /hb/home/swoonna/.local/lib/python3.6/site-packages (from gevent->tensor2tensor) (0.4.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from sympy->tensor2tensor) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos in /hb/home/swoonna/.local/lib/python3.6/site-packages (from tensorflow-metadata->tfds-nightly->tensor2tensor) (1.5.5)\n",
      "Requirement already satisfied: typing>=3.6.4 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from promise->tfds-nightly->tensor2tensor) (3.6.6)\n",
      "Requirement already satisfied: setuptools in /hb/home/swoonna/anaconda3/envs/sbp/lib/python3.6/site-packages (from protobuf->tfds-nightly->tensor2tensor) (40.6.3)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from google-auth>=1.4.1->google-api-python-client->tensor2tensor) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /hb/home/swoonna/.local/lib/python3.6/site-packages (from Jinja2>=2.10->flask->tensor2tensor) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install tensorflow==1.12 --user\n",
    "pip install tensor2tensor --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.6.1\n",
      "alembic==1.0.5\n",
      "astor==0.7.1\n",
      "bsddb3==6.2.6\n",
      "bz2file==0.98\n",
      "cachetools==3.0.0\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "Flask==1.0.2\n",
      "future==0.17.1\n",
      "gast==0.2.1.post0\n",
      "gevent==1.3.7\n",
      "google-api-python-client==1.7.6\n",
      "google-auth==1.6.2\n",
      "google-auth-httplib2==0.0.3\n",
      "googleapis-common-protos==1.5.5\n",
      "greenlet==0.4.15\n",
      "grpcio==1.17.1\n",
      "gunicorn==19.9.0\n",
      "Gutenberg==0.7.0\n",
      "gym==0.10.9\n",
      "httplib2==0.12.0\n",
      "idna==2.8\n",
      "isodate==0.6.0\n",
      "itsdangerous==1.1.0\n",
      "Jinja2==2.10\n",
      "Keras-Applications==1.0.6\n",
      "Keras-Preprocessing==1.0.5\n",
      "Mako==1.0.7\n",
      "Markdown==3.0.1\n",
      "MarkupSafe==1.1.0\n",
      "mesh-tensorflow==0.0.5\n",
      "mpmath==1.1.0\n",
      "nltk==3.4\n",
      "numpy==1.15.4\n",
      "oauth2client==4.1.3\n",
      "pandas==0.23.4\n",
      "promise==2.2.1\n",
      "protobuf==3.6.1\n",
      "pyasn1==0.4.5\n",
      "pyasn1-modules==0.2.2\n",
      "pyglet==1.3.2\n",
      "python-editor==1.0.3\n",
      "pytz==2018.9\n",
      "rdflib==4.2.2\n",
      "rdflib-sqlalchemy==0.3.8\n",
      "requests==2.21.0\n",
      "rsa==4.0\n",
      "scipy==1.2.0\n",
      "singledispatch==3.4.0.3\n",
      "SQLAlchemy==1.2.15\n",
      "sympy==1.3\n",
      "tensor2tensor==1.11.0\n",
      "tensorboard==1.12.2\n",
      "tensorflow==1.12.0\n",
      "tensorflow-gpu==1.12.0\n",
      "tensorflow-metadata==0.9.0\n",
      "tensorflow-probability==0.5.0\n",
      "termcolor==1.1.0\n",
      "tfds-nightly==0.0.2.dev201812180014\n",
      "toolz==0.9.0\n",
      "tqdm==4.29.0\n",
      "typing==3.6.6\n",
      "uritemplate==3.0.0\n",
      "urllib3==1.24.1\n",
      "Werkzeug==0.14.1\n",
      "wrapt==1.10.11\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze --user\n",
    "#python -m pip freeze --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "#import csv\n",
    "pkg_resources.require(\"Tensorflow==1.12.0\")\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# this is what this notebook is demonstrating\n",
    "PROBLEM= 'lang_gen_problem'\n",
    "os.environ['PROBLEM'] = PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf lang_model\n",
    "mkdir -p lang_model/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lang_model/trainer/problem.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lang_model/trainer/problem.py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.models import transformer\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import generator_utils\n",
    "\n",
    "@registry.register_problem\n",
    "class LangGenProblem(text_problems.Text2SelfProblem):\n",
    "\n",
    "  @property\n",
    "  def approx_vocab_size(self):\n",
    "    return 40000  # ~8k\n",
    "\n",
    "  @property\n",
    "  def is_generate_per_split(self):\n",
    "    # generate_data will NOT shard the data into TRAIN and EVAL for us.\n",
    "    return False\n",
    "\n",
    "  @property\n",
    "  def dataset_splits(self):\n",
    "    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n",
    "    # 10% evaluation data\n",
    "    return [{\n",
    "        \"split\": problem.DatasetSplit.TRAIN,\n",
    "        \"shards\": 90,\n",
    "    }, {\n",
    "        \"split\": problem.DatasetSplit.EVAL,\n",
    "        \"shards\": 10,\n",
    "    }]\n",
    "\n",
    "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
    "    with open('data/lang_gen/raw.txt', 'r') as rawfp:\n",
    "        for curr_line in rawfp:\n",
    "            curr_line = curr_line.strip()\n",
    "            if len(curr_line) > 0:       \n",
    "                yield {\n",
    "                    \"targets\": curr_line\n",
    "                }        \n",
    "\n",
    "\n",
    "# Smaller than the typical translate model, and with more regularization\n",
    "@registry.register_hparams\n",
    "def transformer_lang_gen():\n",
    "  hparams = transformer.transformer_base()\n",
    "  hparams.num_hidden_layers = 2\n",
    "  hparams.hidden_size = 128\n",
    "  hparams.filter_size = 512\n",
    "  hparams.num_heads = 4\n",
    "  hparams.attention_dropout = 0.6\n",
    "  hparams.layer_prepostprocess_dropout = 0.6\n",
    "  hparams.learning_rate = 0.05\n",
    "  return hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lang_model/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lang_model/trainer/__init__.py\n",
    "from . import problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ParlAI/setup.py\r\n",
      "#!/usr/bin/env python3\r\n",
      "\r\n",
      "# Copyright (c) 2017-present, Facebook, Inc.\r\n",
      "# All rights reserved.\r\n",
      "# This source code is licensed under the BSD-style license found in the\r\n",
      "# LICENSE file in the root directory of this source tree. An additional grant\r\n",
      "# of patent rights can be found in the PATENTS file in the same directory.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head data/lang_gen/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lang_model/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lang_model/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "  'tensor2tensor'\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='lang_model',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description=\"Lang Gen Problem\",\n",
    "    requires=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch lang_model/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang_model/\r\n",
      "lang_model/setup.py\r\n",
      "lang_model/__init__.py\r\n",
      "lang_model/trainer\r\n",
      "lang_model/trainer/problem.py\r\n",
      "lang_model/trainer/__init__.py\r\n"
     ]
    }
   ],
   "source": [
    "!find lang_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1549925273.531204700 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/text_problems.py:311) preproc_tokenize_training\n",
      ":::MLPv0.5.0 transformer 1549925326.948022366 (/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/text_problems.py:311) preproc_num_train_examples: 275356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "INFO:tensorflow:Importing user module trainer from path /hb/home/swoonna/projects/sbp/code/lang_model\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "/hb/home/swoonna/.local/lib/python3.6/site-packages/tensor2tensor/utils/registry.py:180: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, keywords, _ = inspect.getargspec(rhp_fn)\n",
      "INFO:tensorflow:Generating problems:\n",
      "    lang:\n",
      "      * lang_gen_problem\n",
      "INFO:tensorflow:Generating data for lang_gen_problem.\n",
      "INFO:tensorflow:Generating vocab file: ./t2t_data/vocab.lang_gen_problem.40000.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 3816\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 1752\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 1882\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 1817\n",
      "INFO:tensorflow:Trying min_count 250\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 5853\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 2584\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 2732\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 2673\n",
      "INFO:tensorflow:Trying min_count 125\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 8625\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 3700\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 3839\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 3789\n",
      "INFO:tensorflow:Trying min_count 62\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 12794\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 5316\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 5518\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 5463\n",
      "INFO:tensorflow:Trying min_count 31\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 18366\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 7453\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 7734\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 7641\n",
      "INFO:tensorflow:Trying min_count 15\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 26637\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 10580\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 10874\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 10785\n",
      "INFO:tensorflow:Trying min_count 7\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 39735\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 14867\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 15242\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 15157\n",
      "INFO:tensorflow:Trying min_count 3\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 60355\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 21176\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 21723\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 21580\n",
      "INFO:tensorflow:Trying min_count 1\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 95012\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 28912\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 28912\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 28912\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generating case 100000.\n",
      "INFO:tensorflow:Generating case 200000.\n",
      "INFO:tensorflow:Generated 275356 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=./t2t_data\n",
    "TMP_DIR=$DATA_DIR/tmp\n",
    "rm -rf $DATA_DIR $TMP_DIR\n",
    "mkdir -p $DATA_DIR $TMP_DIR\n",
    "# Generate data\n",
    "t2t-datagen \\\n",
    "  --t2t_usr_dir=./lang_model/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang_gen_problem-dev-00000-of-00010    lang_gen_problem-train-00041-of-00090\r\n",
      "lang_gen_problem-dev-00001-of-00010    lang_gen_problem-train-00042-of-00090\r\n",
      "lang_gen_problem-dev-00002-of-00010    lang_gen_problem-train-00043-of-00090\r\n",
      "lang_gen_problem-dev-00003-of-00010    lang_gen_problem-train-00044-of-00090\r\n",
      "lang_gen_problem-dev-00004-of-00010    lang_gen_problem-train-00045-of-00090\r\n",
      "lang_gen_problem-dev-00005-of-00010    lang_gen_problem-train-00046-of-00090\r\n",
      "lang_gen_problem-dev-00006-of-00010    lang_gen_problem-train-00047-of-00090\r\n",
      "lang_gen_problem-dev-00007-of-00010    lang_gen_problem-train-00048-of-00090\r\n",
      "lang_gen_problem-dev-00008-of-00010    lang_gen_problem-train-00049-of-00090\r\n",
      "lang_gen_problem-dev-00009-of-00010    lang_gen_problem-train-00050-of-00090\r\n",
      "lang_gen_problem-train-00000-of-00090  lang_gen_problem-train-00051-of-00090\r\n",
      "lang_gen_problem-train-00001-of-00090  lang_gen_problem-train-00052-of-00090\r\n",
      "lang_gen_problem-train-00002-of-00090  lang_gen_problem-train-00053-of-00090\r\n",
      "lang_gen_problem-train-00003-of-00090  lang_gen_problem-train-00054-of-00090\r\n",
      "lang_gen_problem-train-00004-of-00090  lang_gen_problem-train-00055-of-00090\r\n",
      "lang_gen_problem-train-00005-of-00090  lang_gen_problem-train-00056-of-00090\r\n",
      "lang_gen_problem-train-00006-of-00090  lang_gen_problem-train-00057-of-00090\r\n",
      "lang_gen_problem-train-00007-of-00090  lang_gen_problem-train-00058-of-00090\r\n",
      "lang_gen_problem-train-00008-of-00090  lang_gen_problem-train-00059-of-00090\r\n",
      "lang_gen_problem-train-00009-of-00090  lang_gen_problem-train-00060-of-00090\r\n",
      "lang_gen_problem-train-00010-of-00090  lang_gen_problem-train-00061-of-00090\r\n",
      "lang_gen_problem-train-00011-of-00090  lang_gen_problem-train-00062-of-00090\r\n",
      "lang_gen_problem-train-00012-of-00090  lang_gen_problem-train-00063-of-00090\r\n",
      "lang_gen_problem-train-00013-of-00090  lang_gen_problem-train-00064-of-00090\r\n",
      "lang_gen_problem-train-00014-of-00090  lang_gen_problem-train-00065-of-00090\r\n",
      "lang_gen_problem-train-00015-of-00090  lang_gen_problem-train-00066-of-00090\r\n",
      "lang_gen_problem-train-00016-of-00090  lang_gen_problem-train-00067-of-00090\r\n",
      "lang_gen_problem-train-00017-of-00090  lang_gen_problem-train-00068-of-00090\r\n",
      "lang_gen_problem-train-00018-of-00090  lang_gen_problem-train-00069-of-00090\r\n",
      "lang_gen_problem-train-00019-of-00090  lang_gen_problem-train-00070-of-00090\r\n",
      "lang_gen_problem-train-00020-of-00090  lang_gen_problem-train-00071-of-00090\r\n",
      "lang_gen_problem-train-00021-of-00090  lang_gen_problem-train-00072-of-00090\r\n",
      "lang_gen_problem-train-00022-of-00090  lang_gen_problem-train-00073-of-00090\r\n",
      "lang_gen_problem-train-00023-of-00090  lang_gen_problem-train-00074-of-00090\r\n",
      "lang_gen_problem-train-00024-of-00090  lang_gen_problem-train-00075-of-00090\r\n",
      "lang_gen_problem-train-00025-of-00090  lang_gen_problem-train-00076-of-00090\r\n",
      "lang_gen_problem-train-00026-of-00090  lang_gen_problem-train-00077-of-00090\r\n",
      "lang_gen_problem-train-00027-of-00090  lang_gen_problem-train-00078-of-00090\r\n",
      "lang_gen_problem-train-00028-of-00090  lang_gen_problem-train-00079-of-00090\r\n",
      "lang_gen_problem-train-00029-of-00090  lang_gen_problem-train-00080-of-00090\r\n",
      "lang_gen_problem-train-00030-of-00090  lang_gen_problem-train-00081-of-00090\r\n",
      "lang_gen_problem-train-00031-of-00090  lang_gen_problem-train-00082-of-00090\r\n",
      "lang_gen_problem-train-00032-of-00090  lang_gen_problem-train-00083-of-00090\r\n",
      "lang_gen_problem-train-00033-of-00090  lang_gen_problem-train-00084-of-00090\r\n",
      "lang_gen_problem-train-00034-of-00090  lang_gen_problem-train-00085-of-00090\r\n",
      "lang_gen_problem-train-00035-of-00090  lang_gen_problem-train-00086-of-00090\r\n",
      "lang_gen_problem-train-00036-of-00090  lang_gen_problem-train-00087-of-00090\r\n",
      "lang_gen_problem-train-00037-of-00090  lang_gen_problem-train-00088-of-00090\r\n",
      "lang_gen_problem-train-00038-of-00090  lang_gen_problem-train-00089-of-00090\r\n",
      "lang_gen_problem-train-00039-of-00090  tmp\r\n",
      "lang_gen_problem-train-00040-of-00090  vocab.lang_gen_problem.40000.subwords\r\n"
     ]
    }
   ],
   "source": [
    "!ls t2t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘lang_model/data’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -r lang_model/data\n",
    "mkdir lang_model/data\n",
    "DATA_DIR=./t2t_data\n",
    "cp ${DATA_DIR}/${PROBLEM}* ${DATA_DIR}/vocab* lang_model/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir lang_model/subset\n",
    "BASE=lang_model/data\n",
    "OUTDIR=lang_model/subset\n",
    "cp \\\n",
    "    ${BASE}/${PROBLEM}-train-0008* \\\n",
    "    ${BASE}/${PROBLEM}-dev-00000*  \\\n",
    "    ${BASE}/vocab* \\\n",
    "    $OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting encoder.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile encoder.sh\n",
    "#!/bin/bash\n",
    "DATA_DIR=lang_model/data\n",
    "OUTDIR=./trained_model\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=lang_model/data \\\n",
    "  --t2t_usr_dir=./lang_model/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_lang_gen \\\n",
    "  --output_dir=$OUTDIR --job-dir=$OUTDIR --train_steps=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sbp.slurm\n"
     ]
    }
   ],
   "source": [
    "%%writefile sbp.slurm\n",
    "#!/bin/bash\n",
    "#note - there can be no empty lines between #SBATCH directives.\n",
    "#SBATCH --job-name=$swoonna-gpu\n",
    "#SBATCH --output=output/encoder.out\n",
    "#SBATCH --error=output/encoder.err\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --mem=80GB\n",
    "#SBATCH --cpus-per-task=10    # CPU cores/threads\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "#SBATCH --mail-user=sanjana_woona@yahoo.co.in\n",
    "#SBATCH --partition=96x24gpu4\n",
    "# The following designates you are using GPU 1 - Tesla P100 model\n",
    "# Please only use 1GPU for 1 job at a time.\n",
    "#SBATCH --gres=gpu:p100:1\n",
    "\n",
    "chmod +x encoder.sh\n",
    "./encoder.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 65120\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch sbp.slurm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "             65120 96x24gpu4 $swoonna  swoonna  R       0:08      1 hbcgpu-021\n"
     ]
    }
   ],
   "source": [
    "!squeue -u swoonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sampling.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile sampling.sh\n",
    "#!/bin/bash\n",
    "# same as the above training job ...\n",
    "OUTDIR=./trained_model \n",
    "DATADIR=./lang_model/data\n",
    "MODEL=transformer\n",
    "\n",
    "BEAM_SIZE=5\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATADIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=transformer_lang_gen \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --t2t_usr_dir=./lang_model/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --hparams='sampling_method=random' \\\n",
    "  --decode_from_file=input.txt \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_gen.slurm\n"
     ]
    }
   ],
   "source": [
    "%%writefile code_gen.slurm\n",
    "#!/bin/bash\n",
    "#note - there can be no empty lines between #SBATCH directives.\n",
    "#SBATCH --job-name=$swoonna-gpu\n",
    "#SBATCH --output=output/decoder.out\n",
    "#SBATCH --error=output/decoder.err\n",
    "#SBATCH --nodes=1\n",
    "# allocate 5GB or RAM on node. You must declare --mem in all scripts\n",
    "#SBATCH --mem=5GB\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "#SBATCH --mail-user=sanjana_woona@yahoo.co.in\n",
    "#SBATCH --partition=96x24gpu4\n",
    "# The following designates you are using GPU 1 - Tesla P100 model\n",
    "# Please only use 1GPU for 1 job at a time.\n",
    "#SBATCH --gres=gpu:p100:1\n",
    "\n",
    "chmod +x sampling.sh\n",
    "./sampling.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 65121\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch code_gen.slurm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "             65120 96x24gpu4 $swoonna  swoonna  R       3:28      1 hbcgpu-021\n",
      "             65121 96x24gpu4 $swoonna  swoonna  R       0:23      1 hbcgpu-021\n"
     ]
    }
   ],
   "source": [
    "!squeue -u swoonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbp)",
   "language": "python",
   "name": "sbp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
